{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scraping Glassdoor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7rvY+yBsvwTGiMotk3uZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Homaoa/From-scraping-to-data-analysis-Glassdoor-website/blob/main/Scraping_Glassdoor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POriaThpwKTv"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mT0zSmDwSH-"
      },
      "source": [
        "#############################\n",
        "#Scraping data from Glassdoor\n",
        "#############################\n",
        "\n",
        "\n",
        "url='https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14_IP1.htm?includeNoSalaryJobs=true'\n",
        "page=1\n",
        "Title=[]\n",
        "City=[]\n",
        "Salary=[]\n",
        "Rating=[]\n",
        "Company=[]\n",
        "\n",
        "\n",
        "while url !=  ('https://www.glassdoor.com/Job/data-scientist-jobs-SRCH_KO0,14_IP31.htm?includeNoSalaryJobs=true'):\n",
        "  source=requests.get(url,headers={'User-Agent':'Mozilla/5.0'}).text\n",
        "  time.sleep(50)\n",
        "\n",
        "  soup=BeautifulSoup(source,'lxml')\n",
        "  #print(soup.prettify())\n",
        "  A=soup.find_all('li',class_=\"react-job-listing css-wp148e eigr9kq3\")\n",
        "\n",
        "  for element in A[1:30]:\n",
        "    try:\n",
        "      header=str(element)\n",
        "      title=header.split('<span>')[-1].split('<')[0]\n",
        "      #print(title)\n",
        "      Title.append(title)\n",
        "    except:\n",
        "      title='NaN'\n",
        "      #print(title)\n",
        "      Title.append(title)\n",
        "\n",
        "\n",
        "  for element in A[1:30]:\n",
        "    try:\n",
        "      header=str(element)\n",
        "      city=header.split('=')[11].split('\"')[1]\n",
        "      #print(city)\n",
        "      City.append(city)\n",
        "    except:\n",
        "      city='NaN'\n",
        "      #print(city)\n",
        "      City.append(city)\n",
        "\n",
        "\n",
        "  for element in A[1:30]:\n",
        "    try:\n",
        "      header=element.find('span',class_='css-1imh2hq e1wijj242').text\n",
        "      salary=header.split('(')[0]\n",
        "      #print(salary)\n",
        "      Salary.append(salary)\n",
        "    except:\n",
        "      salary='NaN'\n",
        "      #print(salary)\n",
        "      Salary.append(salary)\n",
        "\n",
        "\n",
        "  for element in A[1:30]:\n",
        "    try:\n",
        "      rating=element.find('span',class_='css-19pjha7 e1cjmv6j1').text\n",
        "      #print(rating)\n",
        "      Rating.append(rating)\n",
        "    except:\n",
        "      rating='NaN'\n",
        "      #print(rating)\n",
        "      Rating.append(rating)\n",
        "\n",
        "\n",
        "  for element in A[1:30]:\n",
        "    try:\n",
        "      company=element.find('div',class_='d-flex justify-content-between align-items-start').text\n",
        "      #print(company)\n",
        "      Company.append(company)\n",
        "    except:\n",
        "      company='NaN'\n",
        "      #print(company)\n",
        "      Company.append(company)\n",
        "\n",
        "    print()\n",
        "\n",
        "  url=url.replace('_IP'+str(page),'_IP'+str(page+1))\n",
        "  #print(url)\n",
        "  page+=1\n",
        "\n",
        "#print(Title)\n",
        "#print(City)\n",
        "#print(Salary)\n",
        "#print(Rating)\n",
        "#print(Company)\n",
        "\n",
        "dict={'Title':Title,'City':City,'Salary':Salary,'Rating':Rating,'Company':Company}\n",
        "df = pd.DataFrame(dict) \n",
        "df.to_csv('glassdoor_scrape.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j23zkhHTxP4H"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    }
  ]
}